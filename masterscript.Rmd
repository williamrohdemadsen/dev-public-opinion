---
title: "masterscript"
author: "William Rohde Madsen"
output: html_document
---

# Packages
```{r loading packages, echo = FALSE, include = FALSE}
library(tidyverse)
library(readxl)
library(lubridate)
library(stringr)
library(janitor)
library(rgdal) # for shapefiles
library(sf)
library(lme4) # for glmer, etc. modelling
library(rtweet) # using Twitter API
library(httr)
library(tfse) # to save token to environment
library(ggrepel)

#source("src/theme.R")

```

# Load data
## Supplementary data
```{r load-supp}
###### Load supplementary data

# Language data from the UN
lang_raw <- read_csv("data/raw/UNdata_Export_20210203_194758725.csv")

# Language data pasted from Ethnologue
ethno_raw <- read_excel("data/raw/ethnologue_english.xlsx")

# Corruption perception index
cpi_raw <- read_excel("data/raw/CPI2020_GlobalTablesTS_210125.xlsx",
                      sheet = "CPI Timeseries 2012 - 2020",
                      skip = 2)

# UN population estimates
## https://population.un.org/wpp/Download/Standard/CSV/
pop_raw <- read_csv("data/raw/WPP2019_TotalPopulationBySex.csv")

# GDP PPP from World Bank
## https://data.worldbank.org/indicator/NY.GDP.MKTP.PP.KD
gdp_ppp_raw <- read_csv("data/raw/API_NY.GDP.MKTP.PP.KD_DS2_en_csv_v2_1928416.csv", skip = 3)

```

## Leader data
```{r load-leader}
###### Load leader data
reign_raw <- read_csv("https://cdn.rawgit.com/OEFDataScience/REIGN.github.io/gh-pages/data_sets/leaderlist_1_21.csv")

```

# Format supplemenary data
```{r format-supp}
###### Format and bind supplementary data
# This will serve to decide and describe the countries in focus

###### Clean
# UN language population
## Appears to only show population by primary language
## May use rural, urban distinctions for weighting
lang_raw %>%
  clean_names() %>%
  filter(language %in% c("Total", "English")) %>%
  mutate(value = round(value)) %>%
  pivot_wider(names_from = language, values_from = value) %>%
  clean_names() %>%
  mutate(english_prop = english/total %>% round) %>%
  rename(country = country_or_area) %>%
  group_by(country, area, sex) %>%
  filter(year == max(year))

# Ethnologue language data, English speakers
ethno <- ethno_raw %>%
  mutate(country = if_else(grepl("Hide Details", English), gsub("Hide Details", "", English), NA_character_),
         country = if_else(English == "English", "United Kingdom", country),
         name = lag(English),
  ) %>%
  fill(country, name) %>%
  filter(lag(English) %in% c("User Population", "Location", "Language Status", "Other Comments")) %>%
  pivot_wider(names_from = name, values_from = English) %>%
  clean_names() %>%
  mutate(eng_total = gsub(" .+", "", user_population) %>% gsub(",", "", .) %>% as.integer,
         l1 = if_else(grepl("L1", user_population),
                      gsub(".+ L1 users: ", "", user_population),
                      NA_character_),
         l1_src = str_extract(l1,  "(?<=\\().+?(?=\\))"),
         l1 = sub(" .+", "", l1) %>% gsub(",", "", .) %>% as.integer,
         l1_yr = str_extract(l1_src, "\\d+") %>% as.integer,
         l2 = if_else(grepl("L2", user_population),
                      gsub(".+ L2 users: ", "", user_population),
                      NA_character_),
         l2_src = str_extract(l2,  "(?<=\\().+?(?=\\))"),
         l2 = sub(" .+", "", l2) %>% gsub(",", "", .) %>% as.integer,
         l2_yr = str_extract(l2_src, "\\d+") %>% as.integer,
         total_yr = if_else(l2 > l1, l2_yr, l1_yr),
         total_yr = if_else(is.na(total_yr), l2_yr, total_yr) %>% if_else(is.na(.), l1_yr, .),
         total_src = if_else(is.na(l1_src) & is.na(l2_src),
                             str_extract(user_population,  "(?<=\\().+?(?=\\))"),
                             NA_character_),
         total_yr = if_else(is.na(total_yr),
                            str_extract(total_src, "\\d+") %>% as.integer,
                            total_yr)
  )

## Subset key variables
ethno_sub <- ethno %>%
  select(country, eng_total, total_yr)

# Corruption
cpi <- cpi_raw %>%
  clean_names() %>%
  rename_with(~if_else(str_count(., "_") == 2, sub("_", "", .), .)) %>% # remove first _ for those with two
  pivot_longer(c(4:ncol(.)),
               names_to = c(".value", "year"),
               names_pattern = "(.+)_(.+)") %>%
  transmute(country, year = as.double(year), cpiscore)

# UN population estimates
pop <- pop_raw %>%
  clean_names() %>%
  rename(country = location, year = time) %>%
  mutate(across(c(7:10), ~.*1000)) %>%
  filter(variant == "Medium") %>%
  filter(year %in% c(1989:2021)) %>%
  select(country, year, pop_total)

# GDP PPP data
gdp_ppp <- gdp_ppp_raw %>%
  pivot_longer(c(5:ncol(.)), names_to = "year", values_to = "gdp_ppp") %>%
  clean_names() %>%
  filter(gdp_ppp != "X66") %>%
  transmute(country = country_name, year = as.integer(year), gdp_ppp)

###### Bind
supp <- cpi %>%
  full_join(ethno_sub, by = c("country", "year" = "total_yr")) %>%
  left_join(pop, by = c("country", "year")) %>%
  left_join(gdp_ppp, by = c("country", "year")) %>%
  mutate(eng_prop = eng_total/pop_total,
         gdp_ppp_pc = gdp_ppp/pop_total
         ) %>%
  filter(!is.na(eng_prop))
  
  
  
```


```{r plot-supp}
###### Plot English speaking population against corruption index
supp %>%
  ggplot(.,
         aes(x = gdp_ppp_pc,
             y = eng_prop)) +
  geom_point() +
  geom_label_repel(aes(label = paste0(country, " ", year))
                   ) +
  facet_wrap(~year)



```

# Get Tweets
```{r auth-twitter}
###### Twitter authentication
# Authorise
vignette("auth", package = "rtweet")

## Key and secret
api_key <- "edoqgFncKJGs99qm7f3eDc7Uk"
api_secret_key <- "njtGrg5VI5TWtbF1dHe6sYE9AL0y5TAyDURhC0d4RLjwfdyzhx"
access_token <- "1112111731562688523-qcQjmeFZVFItfNEWG4QrdyhphTaWy0"
access_token_secret <- "JIFj9xvlFWNh6RBGiqf4IANlvtCX1CgBZ3YQmmCaSjd4T"

## Create app object
app <- httr::oauth_app(appname = "APP_WM",
                       key = api_key,
                       secret = api_secret_key)

## Access token method
token <- httr::Token1.0$new(app = app,
                            endpoint = httr::oauth_endpoints("twitter"),
                            params = list(as_header = TRUE),
                            credentials = list(oauth_token = access_token,
                                               oauth_token_secret = access_token_secret),
                            cache = FALSE)
token




```

```{r get-tweets}
###### Get Tweets

###### Google Maps look-up coordinates
# Using Google Maps API to find coordinates of a country
google_maps_key <- "AIzaSyDTdau8NxUxOuIJrQ_bq0AbVkLisb3QkqM"
nigeria_geo <- lookup_coords("nigeria", apikey = google_maps_key)

##### Get Nigeria tweets
# Recent
nigeria_tweets <- search_tweets("buhari lang:en OR Buhari lang:en", include_rts = FALSE, geocode = nigeria_geo, n = 30)

# Full-archieve
#search_fullarchive

# tweets$created_at <- as.POSIXct(strptime(tweets$created_at, format = "%m/%d/%Y %H:%M:%S"))
# tweets$account_created_at <- as.POSIXct(strptime(tweets$account_created_at, format = "%m/%d/%Y %H:%M:%S"))
# tweets$quoted_created_at <- as.POSIXct(strptime(tweets$quoted_created_at, format = "%m/%d/%Y %H:%M:%S"))
# tweets_2 <- tweets %>%
#   group_by(status_id) %>%
#   mutate_all(~ if_else(is.list(.) & , paste(.), .))

```


# Format data
```{r format-tweets}
###### Tidy and format tweets
nigeria_tweets %>% names

```

# Analysis
## Tweet analysis
```{r sentiment-analysis}
###### Analyse sentiment for Tweets


```

```{r extract-covariates}
###### Extract individual-level covariates


```

