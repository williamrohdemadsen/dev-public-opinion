---
title: "masterscript"
author: "William Rohde Madsen"
output: html_document
---

# Packages
```{r loading packages, echo = FALSE, include = FALSE}
library(tidyverse)
library(readxl)
library(lubridate)
library(stringr)
library(janitor)
library(rgdal) # for shapefiles
library(sf)
library(lme4) # for glmer, etc. modelling
library(rtweet) # using Twitter API
library(httr)
library(tfse) # to save token to environment

#source("src/theme.R")

```

# Load data
## Supplementary data
```{r load-supp}
###### Load supplementary data

# Language data from the UN
lang_raw <- read_csv("data/raw/UNdata_Export_20210203_194758725.csv")

# Corruption perception index
cpi_raw <- read_excel("data/raw/CPI2020_GlobalTablesTS_210125.xlsx",
                      sheet = "CPI Timeseries 2012 - 2020",
                      skip = 2)

```

## Leader data
```{r load-leader}
###### Load leader data
reign_raw <- read_csv("https://cdn.rawgit.com/OEFDataScience/REIGN.github.io/gh-pages/data_sets/leaderlist_1_21.csv")

```

# Format supplemenary data
```{r format-supp}
###### Format and merge language and corruption data
# This will serve to decide and describe the countries in focus

###### Clean
# Languages
lang_raw %>%
  clean_names() %>%
  filter(language %in% c("Total", "English")) %>%
  mutate(value = round(value)) %>%
  pivot_wider(names_from = language, values_from = value) %>%
  clean_names() %>%
  mutate(english_prop = english/total %>% round) %>%
  rename(country = country_or_area) %>%
  group_by(country_or_area, area, sex, record_type, reliability) %>%
  filter(year == max(year)) %>%
  view()


###### Merge


```



# Get Tweets
```{r auth-twitter}
###### Twitter authentication
# Authorise
vignette("auth", package = "rtweet")

## Key and secret
api_key <- "edoqgFncKJGs99qm7f3eDc7Uk"
api_secret_key <- "njtGrg5VI5TWtbF1dHe6sYE9AL0y5TAyDURhC0d4RLjwfdyzhx"
access_token <- "1112111731562688523-qcQjmeFZVFItfNEWG4QrdyhphTaWy0"
access_token_secret <- "JIFj9xvlFWNh6RBGiqf4IANlvtCX1CgBZ3YQmmCaSjd4T"

## Create app object
app <- httr::oauth_app(appname = "APP_WM",
                       key = api_key,
                       secret = api_secret_key)

## Access token method
token <- httr::Token1.0$new(app = app,
                            endpoint = httr::oauth_endpoints("twitter"),
                            params = list(as_header = TRUE),
                            credentials = list(oauth_token = access_token,
                                               oauth_token_secret = access_token_secret),
                            cache = FALSE)
token




```

```{r get-tweets}
###### Get Tweets

###### Google Maps look-up coordinates
# Using Google Maps API to find coordinates of a country
google_maps_key <- "AIzaSyDTdau8NxUxOuIJrQ_bq0AbVkLisb3QkqM"
nigeria_geo <- lookup_coords("nigeria", apikey = google_maps_key)

##### Get Nigeria tweets
# Recent
nigeria_tweets <- search_tweets("buhari lang:en OR Buhari lang:en", include_rts = FALSE, geocode = nigeria_geo, n = 30)

# Full-archieve
#search_fullarchive

# tweets$created_at <- as.POSIXct(strptime(tweets$created_at, format = "%m/%d/%Y %H:%M:%S"))
# tweets$account_created_at <- as.POSIXct(strptime(tweets$account_created_at, format = "%m/%d/%Y %H:%M:%S"))
# tweets$quoted_created_at <- as.POSIXct(strptime(tweets$quoted_created_at, format = "%m/%d/%Y %H:%M:%S"))
# tweets_2 <- tweets %>%
#   group_by(status_id) %>%
#   mutate_all(~ if_else(is.list(.) & , paste(.), .))

```


# Format data
```{r format-tweets}
###### Tidy and format tweets
nigeria_tweets %>% names

```

# Analysis
## Tweet analysis
```{r sentiment-analysis}
###### Analyse sentiment for Tweets


```

```{r extract-covariates}
###### Extract individual-level covariates


```

