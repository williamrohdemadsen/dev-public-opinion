---
title: "dev-public-opinion"
author: "William Rohde Madsen"
output: html_document
---

# Set up
```{r set-up}
# Load packages
library(tidyverse)
library(devtools)
library(readxl)
library(lubridate)
library(stringr)
library(janitor)
library(zoo)
library(RcppRoll)
library(rgdal) # for shapefiles
library(sf) # manipulating spatial data
library(lme4) # for glmer, etc. modelling
library(httr)
library(ggrepel)
library(reticulate) # using python code in R
library(vroom) # loading json faster
library(ndjson)
library(jsonlite)
library(rvest) # reading html websites
library(maps)
library(ggmap)
library(stars) # rasters
library(maptools)
library(spatstat)
library(koRpus)
library(quanteda)
library(textdata)
library(tidytext)
library(SnowballC)
library(furrr)
library(data.table)
require(scales)
library(patchwork)

# Load package functions
#devtools::load_all()

```

# Load prepared data
```{r load-data}
# Load formatted data
# Formatted with R scripts in data-raw
#load("data/formatted_data.RData")

load("data/formatted_gadm.RData")

load("data/formatted_supplementary.RData")

load("data/tweets_sf.RData")

tweets_sub <- fread("data/tweets_sub.csv") 

senti_tokens <- fread("data/senti_tokens.csv")

```


```{r source-scripts}
# Source R scripts
list.files("R", full.names = TRUE) %>%
  purrr::map(source)

```


# Sentiment analysis

```{r senti-per-tweet}
# Calculate sentiment per Tweet
# Mean sentiment per Tweet
senti_tweet <- calculate_sentiment_per_tweet(senti_tokens)

```

```{r add-regions}
# Add regions to sentiment
senti_tweet_w_region_sf <- add_regions(senti_tweet, boundaries_subnational)

# Convert to data.table()
senti_tweet_w_region <- as.data.table(senti_tweet_w_region_sf) %>%
  select(-geometry)

```


# Sentiment per day
```{r senti-day}
# Sentiment per day
senti_day <- calculate_sentiment_per_day(senti_tweet_w_region)

senti_day

# Regions included in data
senti_day$region_1 %>% unique %>% paste(., collapse = ", ")

```


# Sentiment per region over time
```{r senti-region}
# Sentiment per region adjusted over time
# Based on regions
# average sentiment per region
# using non-point tweets to show trend over time
senti_region <- create_region_adjusted_sentiment(senti_day)

senti_region %>% arrange(region_1) %>% distinct(region_1) %>% paste

# Linear interpolation to make up for missing days
# interpolate_missing_days()

```


# Raw estimates
```{r raw-estimates}
# Find for-against based on mean sentiment
senti_cut_offs <- create_cut_offs(senti_tweet_w_region)

#senti_cut_offs <- senti_cut_offs[1:10000,]

# Create raw number of pros and cons per day
raw_n_day <- calculate_raw_n_per_day(senti_cut_offs)

# Calculate raw estimate per day
raw_day <- calculate_raw_estimate_per_day(raw_n_day, n_roll = 7)

raw_day %>% filter(is.na(country))

# Add national level
raw_day <- add_national_level(raw_day)

# Plot pro-share by cut-offs
raw_day %>%
  filter(leader == "Ghani") %>%
  ggplot(., aes(x = date, y = pro_share)) +
  geom_point(colour = "red") +
  geom_line(aes(y = pro_share_roll), colour = "black") +
  facet_wrap(~ cut_off) +
  labs(title = "Ghani's raw favourability rate by raw estimates and different cut offs",
       subtitle = "Estimated favourability of Afghan leader Ghani by raw sentiment and different cut offs") +
  theme_devpublicopinion


```

```{r add-targets-to-raw}
# Add targets (election results and polls)
# Join sentiment with target vector, election and polling results
raw_day <- raw_day %>%
  mutate(target_id = row_number())

nrow(raw_day)

raw_day_targets_all <- join_targets(raw_day, targets_master)

# Check which senti regions are not in targets object
raw_day %>% filter(!region_1 %in% targets_master$region_1) %>% distinct(country, region_1)

# Select nearest target (election or poll) for each day
raw_day_targets <- select_nearest_target(raw_day_targets_all)

nrow(raw_day_targets) # number of rows after finding nearest target 

raw_day_targets <- raw_day_targets %>%
  # create variable with country and region_1
  mutate(year = year(date),
         country_and_region_1 = paste0(country, "_", region_1))

# Add GDL covariates
raw_day_targets_covars <- add_gdl_covariates(raw_day_targets, gdl_interpo)

# Check if regions are missing GDL statistics
raw_day_targets_covars %>% filter(is.na(popshare)) %>% distinct(region_1)


```


```{r validate-raw}
# Validate raw

# Summary statistics of each cut-off
raw_mae <- mae_by_cut_offs(raw_day_targets_covars, type = "election", days_diff_less = 10)

# Plot raw estimate stats of each cut-off
raw_mae %>%
  mutate(country_elex = paste0(country, ", ", format(date_target, "%B %Y"))) %>%
  ggplot(.,
         aes(x = cut_off, y = mean*100)) +
  geom_col() +
  #geom_smooth(method = lm) +
  facet_wrap(~ country_elex) +
  labs(title = "Mean absolute error of 'raw' electoral estimates at different AFINN cut offs",
       subtitle = "Mean absolute error (MAE) of election estimates based on 'raw' AFINN sentiment, percentage points",
       x = "Cut off values",
       y = "MAE"
  ) +
  theme_devpublicopinion


```


# Add targets to sentiment
```{r add-to-senti-day}
# Add targets (election results and polls)
# Join sentiment with target vector, election and polling results
senti_day <- senti_day %>%
  mutate(target_id = row_number())

senti_day <- add_national_level(senti_day)

nrow(senti_day)

senti_day_targets_all <- join_targets(senti_day, targets_master)

# Check which senti regions are not in targets object
senti_day %>% filter(!region_1 %in% targets_master$region_1) %>% distinct(country, region_1)

# Select nearest target (election or poll) for each day
senti_day_targets <- select_nearest_target(senti_day_targets_all)

nrow(senti_day_targets) # number of rows after finding nearest target 

senti_day_targets <- senti_day_targets %>%
  # create variable with country and region_1
  mutate(year = year(date),
         country_and_region_1 = paste0(country, "_", region_1))

# Add GDL covariates
senti_day_targets_covars <- add_gdl_covariates(senti_day_targets, gdl_interpo)

# Check if regions are missing GDL statistics
senti_day_targets_covars %>% filter(is.na(popshare)) %>% distinct(region_1)


```


```{r add-to-senti-region}
# Add targets (election results and polls)
senti_region <- senti_region %>%
  mutate(target_id = row_number())

senti_region_targets_all <- join_targets(senti_region, targets_master)

# Check which senti regions are not in targets object
senti_region %>% filter(!region_1 %in% targets_master$region_1) %>% distinct(country, region_1)

# Select nearest target (election or poll) for each day
senti_region_targets <- select_nearest_target(senti_region_targets_all)

# Compare rows, new rows indicate targets being of equal diff days to a sentiment day
nrow(senti_region)
nrow(senti_region_targets)

senti_region_targets <- senti_region_targets %>%
  # create variable with country and region_1
  mutate(year = year(date),
         country_and_region_1 = paste0(country, "_", region_1))

# Add GDL covariates
senti_region_targets_covars <- add_gdl_covariates(senti_region_targets, gdl_interpo)

# Check if regions are missing GDL statistics
senti_region_targets_covars %>% filter(is.na(popshare)) %>% distinct(region_1)


```

```{r print-elex-per-country}
# Elections for each country
senti_targets_covars %>%
  filter(type == "election") %>%
  distinct(country, date_target) %>%
  arrange(country)

```


# Multilevel regression
```{r mr-model-day}
# Multilevel models based on sentiment day

# Training data
# Sentiment day
train_data_elex_first_day <- create_training_data(senti_day_targets_covars, type = "elex")
train_data_polls_day <- create_training_data(senti_day_targets_covars, type = "polls")

# Sentiment 

# Fit models
# Trained on election results
mr_day_elex_1 <- lmer(votes_share ~ afinn_mean + (1 | country),
                      data = train_data_elex_first_day)

mr_day_elex_2 <- lmer(votes_share ~ afinn_mean + (1 + afinn_mean | country),
                      data = train_data_elex_first_day)

mr_day_elex_3 <- lmer(votes_share ~ afinn_mean + n_likes_mean + (1 + afinn_mean | country),
                      data = train_data_elex_first_day)

mr_day_elex_4 <- lmer(votes_share ~ afinn_mean + days_diff_abs + (1 + afinn_mean | country),
                      data = train_data_elex_first_day)

# Trained on polls
mr_day_polls_1 <- lmer(votes_share ~ afinn_mean + (1 | country),
                       data = train_data_polls_day)

mr_day_polls_2 <- lmer(votes_share ~ afinn_mean + (1 + afinn_mean | country),
                       data = train_data_polls_day)


```


```{r mr-model-region}
# Multilevel models based on sentiment region based

# Training data
# Sentiment day
train_data_elex_first_region <- create_training_data(senti_region_targets_covars, type = "elex")
train_data_polls_region <- create_training_data(senti_region_targets_covars, type = "polls")

# Sentiment 

# Fit models
# Trained on election results
mr_day_elex_1 <- lmer(votes_share ~ afinn_mean + (1 | country),
                      data = train_data_elex_first)

mr_day_elex_2 <- lmer(votes_share ~ afinn_mean + (1 + afinn_mean | country),
                      data = train_data_elex_first)

# Trained on polls
mr_day_polls_1 <- lmer(votes_share ~ afinn_mean + (1 | country),
                       data = train_data_polls)

mr_day_polls_2 <- lmer(votes_share ~ afinn_mean + (1 + afinn_mean | country),
                       data = train_data_polls)


```

```{r validate-mr}
# Validate poll-based models

# Predict model 1
predictions_1 <- test_data_elex_last %>%
  mutate(prediction_1_elex_1 = predict(model_1_elex_1, ., allow.new.levels = TRUE),
         prediction_1_elex_2 = predict(model_1_elex_2, ., allow.new.levels = TRUE),
         prediction_1_polls_1 = predict(model_1_polls_1, ., allow.new.levels = TRUE),
         prediction_1_polls_2 = predict(model_1_polls_2, ., allow.new.levels = TRUE)
         
  )

# Calculate MAE on validation data
(mae_1 <- predictions_1 %>%
    #filter(days_diff_abs < 40) %>%
    mutate(diff_1_elex_1 = abs(prediction_1_elex_1 - votes_share),
           diff_1_elex_2 = abs(prediction_1_elex_2 - votes_share),
           diff_1_polls_1 = abs(prediction_1_polls_1 - votes_share),
           diff_1_polls_2 = abs(prediction_1_polls_2 - votes_share),
    ) %>%
    group_by(country, date_target) %>%
    summarise(across(starts_with("diff"), ~mean(., na.rm = TRUE))) %>%
    ungroup()
)

```


# MRP
```{r mrp-models}
# Multilevel regression with post-stratification
model_2_1 <- lmer(votes_share ~ afinn_mean + (1|country_and_region_1),
                  data = train_data_1)

summary(model_2_1)

# Predict on test data
predictions_2 <- predictions %>%
  filter(type == "election") %>%
  filter(days_diff_abs < 10) %>%
  filter(!(country == "Zimbabwe" & year(date) == 2013)) %>%
  mutate(prediction_2_1 = predict(model_2_1, ., allow.new.levels = TRUE)
  )

# Post-stratify using GDL's population share
predictions_2 <- predictions_2 %>%
  transmute(prediction_2_1, popshare/100, prediction_2_1_weighted = prediction_2_1*popshare/100)



```




```{r validate-mrp}

```


# Tables
```{r table-country-stats}
# Table of country statistics
tweets_stats_country <- tweets_sub %>%
  transmute(leader_country,
            week = floor_date(date, "week"),
            year = year(date),
            week_country = paste0(leader_country, week),
            year_country = paste0(leader_country, year)
  )

add_total <- function(x) { mutate(x, Total = Afghanistan + Georgia + Mexico + Nigeria + Zimbabwe) }

# tweets_total <- tweets_sub %>%
#   mutate(leader_country = "Total")
# 
# tweets_stats_country <- rbind(tweets_stats_country, tweets_total)

# Tweet count per country
(n_tweets_per_country <- tweets_stats_country %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Total tweets") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Average number of tweets per country
(n_weekly_tweets_per_country <- rbind(tweets_stats_country,
                                      tweets_stats_country %>% mutate(leader_country = "Total")) %>%
    group_by(leader_country, week_country) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = mean(n) %>% round(2)) %>%
    mutate(variable = "Average weekly number of tweets") %>%
    pivot_wider(names_from = leader_country, values_from = n)
)

# Number of unique weeks
(n_weeks_per_country <- tweets_stats_country %>%
    group_by(leader_country, week) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of weeks") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Years per country
(n_years_per_country <- tweets_stats_country %>%
    group_by(leader_country, year) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of years") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Subnational regions per country in data
(n_regions_1_per_country <- tweets_sf %>%
    as.data.frame() %>%
    select(-geometry) %>%
    group_by(leader_country, region_1) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of subnational regions/levels") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Number of elections per country
(n_elections_per_country <- elex_master %>%
    group_by(country, elex_date) %>%
    summarise(n = n()) %>%
    group_by(country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of elections") %>%
    pivot_wider(names_from = country, values_from = n) %>%
    add_total()
)

# Number of unique candidacies and leaders
(n_candidates_per_country <- candidates %>%
    group_by(country, name, elex_date) %>%
    summarise(n = n()) %>%
    group_by(country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of elections per country") %>%
    pivot_wider(names_from = country, values_from = n) %>%
    add_total()
)

# Number of polls per country
(n_polls_per_country <- polling_master %>%
    group_by(country, date) %>%
    summarise(n = n()) %>%
    group_by(country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of polls per country") %>%
    pivot_wider(names_from = country, values_from = n) %>%
    add_total()
)

# Combine into table
(by_country_table <- bind_rows(n_tweets_per_country,
                               n_weekly_tweets_per_country,
                               n_weeks_per_country,
                               n_years_per_country,
                               n_regions_1_per_country,
                               #n_regions_2_per_country,
                               n_elections_per_country,
                               n_polls_per_country) %>%
    rename(Name = variable)
)

# Save as csv
#write_csv(by_country_table, file = "output/tables/per_country.csv")


```



```{r model-tabel}
# Table to compare models


#tidy()

```


# Plots

```{r plot-polls-and-elex}
# Plot traditional polling and election results

# Subset database to include national level rows, only polls
poll_plot_data <- targets_master %>%
  filter(name %in% candidates$name) %>%
  filter(region_1 == "National") %>%
  filter(type == "poll") %>%
  mutate(votes_share = votes_share*100)

# Add US polls for comparison
poll_plot_data <- bind_rows(poll_plot_data,
                            polling_us %>%
                              mutate(votes_share = votes_share*100) %>%
                              filter(year(date_target) > 2006))

# Plot
ggplot(poll_plot_data,
       aes(x = date_target,
           y = votes_share)) +
  geom_point(aes(colour = name), show.legend = FALSE,
             size = 3, shape = 20) +
  geom_label_repel(data = poll_plot_data %>% group_by(name) %>% slice_sample(n = 1),
                   min.segment.length = 0.5,
                   size = 5,
                   aes(x = date_target, y = votes_share, label = name)) +
  facet_wrap(~country# , scales = "free"
  ) +
  theme_devpublicopinion +
  labs(title = "Polling for developing countries is sparce over time",
       subtitle = "% vote share, point for each traditional polling collected by country; numbers of polls included in this figure are not exhaustive",
       x = NULL,
       y = "%, vote share")


```

```{r plot-model-estimates-vs-polls-and-elex}
# Plot model estimates versus polling and election results



```


```{r plot-weekly-tweet-frequency}
# Summarise tweets per week
tweets_n_per_week <- tweets_sub %>%
  group_by(leader_country, leader, week = floor_date(date, "week")) %>%
  summarise(n = n()) %>%
  ungroup()

# Mean number of tweets per week
tweets_n_per_week %>%
  group_by(week) %>%
  summarise(mean = mean(n))

# Plot
ggplot(tweets_n_per_week, aes(x = week, y = n)) +
  geom_col(colour = blue_colour) +
  facet_wrap(~ leader_country,
             scales = "free_y",
             labeller = label_wrap_gen(width = 20),
             #space = "free"
  ) +
  labs(title = "Weekly number of Tweets per country",
       subtitle = "Number of Tweets per week by country of the leader mentioned in the Tweet") +
  theme_devpublicopinion +
  ggsave("output/figures/tweets_n_per_week.png")


```


```{r plot-tweets-by-having-points}
# Number of tweets over time
tweets_sf %>%
  as.data.frame() %>%
  group_by(has_point, year = year(date)) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  mutate(has_point = case_when(has_point ~ "Geotagged",
                               !has_point ~ "Non-geotagged")) %>%
  ggplot(., aes(x = year, y = n)) +
  geom_col(aes(fill = has_point), show.legend = FALSE) +
  facet_wrap(~has_point, scales = "free_y"
  ) +
  scale_y_continuous(labels = comma) +
  labs(title = "Number of tweets with or without coordinates",
       subtitle = "Number of Tweets per year that were geotagged or not by the Twitter users"
  ) +
  theme_devpublicopinion +
  ggsave("output/figures/number_of_tweets_has_point.png")


```


```{r senti-join-stats}
# Share of tweets with no lexicon match for any of their stemmed words
(share_tweets_no_senti <- senti_tweets %>%
   group_by(id, username, language) %>%
   summarise(afinn_mean = mean(afinn_value, na.rm = TRUE)) %>%
   mutate(has_afinn = !is.na(afinn_mean),
          in_english = language == "en") %>%
   group_by(has_afinn, in_english) %>%
   summarise(n = n())
)

```



```{r plot-maps}
# Simply GADM for plotting ease
boundaries_subnational_simp <- boundaries_subnational %>%
  st_simplify(., dTolerance = 0.05)

# Plot geotagged Tweets on map
tweets_geotagged <- tweets_sf %>%
  filter(has_point)

plot_tweets_in_country <- function(plot_country = "Afghanistan"){
  
  ggplot() +
    geom_sf(data = boundaries_subnational_simp %>% filter(country == plot_country),
            fill = NA) +
    geom_sf(data = tweets_geotagged %>% filter(country == plot_country),
            size = 3, shape = 21, fill = blue_colour) +
    labs(title = paste0(plot_country)) +
    theme_devpublicopinion +
    theme(panel.grid.major = element_blank())
  
}

# Plot and combine maps by country with patchwork
(map_afg <- plot_tweets_in_country("Afghanistan"))
map_zwe <- plot_tweets_in_country("Zimbabwe")
map_geo <- plot_tweets_in_country("Georgia")
map_mex <- plot_tweets_in_country("Mexico")
map_nga <- plot_tweets_in_country("Nigeria")


(map_afg | map_mex | map_zwe)/(map_geo | map_nga) +
  plot_annotation(title = "Geotagged Tweets by country and subnational regions",
                  subtitle = "The spatial location of geotagged Tweets that mentions a country leader or election candidate",
                  theme = theme_devpublicopinion
  ) +
  ggsave("output/figures/maps.png")


```



```{r plot-point-mae-by-election}
# Point plot of MAE by elections
# Highlight problematic/special elections (ZWE 2013)


```



```{r plot-eng-speakers}
# English-speakers plot
# Plot different data on English speakers
supp %>%
  ggplot(.,
         aes(x = eng_prop_wiki,
             y = eng_prop) # ethno
  ) +
  geom_point() +
  geom_label_repel(aes(label = paste0(country, " ", year))) +
  labs(title = "Different sources on English speakers per country")

# Plot English speaking population against corruption index
supp %>%
  #filter(wgi_est < 1) %>%
  filter(twitter_users_pc < 0.3) %>%
  ggplot(.,
         aes(x = twitter_users_pc,
             y = eng_prop)) +
  geom_point() +
  geom_label_repel(aes(label = paste0(country, " ", year))) +
  labs(title = "English-speaking share by voice and accountability index")

```


