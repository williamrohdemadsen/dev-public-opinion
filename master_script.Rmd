---
title: "dev-public-opinion"
author: "William Rohde Madsen"
output: html_document
---

# Set up
```{r set-up}
# Load packages
library(tidyverse)
library(devtools)
library(readxl)
library(lubridate)
library(stringr)
library(janitor)
library(zoo)
library(RcppRoll)
library(rgdal) # for shapefiles
library(sf) # manipulating spatial data
library(lme4) # for glmer, etc. modelling
library(httr)
library(ggrepel)
library(reticulate) # using python code in R
library(vroom) # loading json faster
library(ndjson)
library(jsonlite)
library(rvest) # reading html websites
library(maps)
library(ggmap)
library(stars) # rasters
library(maptools)
library(spatstat)
library(koRpus)
library(quanteda)
library(textdata)
library(tidytext)
library(SnowballC)
library(furrr)
library(data.table)
require(scales)
library(patchwork)

# Load package functions
#devtools::load_all()

```

# Load prepared data
```{r load-data}
# Load formatted data
# Formatted with R scripts in data-raw
#load("data/formatted_data.RData")

load("data/formatted_gadm.RData")

load("data/formatted_supplementary.RData")

load("data/tweets_sf.RData")

tweets_sub <- fread("data/tweets_sub.csv") 

senti_tokens <- fread("data/senti_tokens.csv")

```


```{r source-scripts}
# Source R scripts
list.files("R", full.names = TRUE) %>%
  purrr::map(source)

```


# Sentiment analysis

```{r senti-per-tweet}
# Calculate sentiment per Tweet
# Mean sentiment per Tweet
senti_tweet <- calculate_sentiment_per_tweet(senti_tokens)

```

```{r add-regions}
# Add regions to sentiment
senti_tweet_sf <- add_regions(senti_tweet, boundaries_subnational)

```


# Sentiment per day
```{r senti-day}
# Sentiment per day
senti_day <- calculate_sentiment_per_day(senti_tweet_sf)

senti_day

# Regions included in data
senti_day$region_1 %>% unique %>% paste(., collapse = ", ")

```


# Sentiment per region over time
```{r senti-region}
# Sentiment per region adjusted over time
# Based on regions
# average sentiment per region
# using non-point tweets to show trend over time
senti_day_region_adj <- create_region_adjusted_sentiment(senti_day)

senti_day_region_adj %>% arrange(region_1) %>% distinct(region_1) %>% paste

# Linear interpolation to make up for missing days
#interpolate_missing_days()

```


# Raw estimates
```{r raw-estimates}
# Find for-against based on mean sentiment
senti_cut_offs <- create_cut_offs(senti_tweet_sf)

#senti_cut_offs <- senti_cut_offs[1:10000,]

# Create an estimate per week per cut off
raw_estimates <- calculate_raw_estimates(senti_cut_offs, n_roll = 5)

# Plot pro-share by cut-offs
raw_estimates %>%
  filter(leader == "Ghani") %>%
  ggplot(., aes(x = date, y = pro_share, colour = leader)) +
  geom_point() +
  geom_line(aes(y = pro_share_roll), colour = "black") +
  facet_wrap(~ cut_off) +
  labs(title = "Raw estimates based on sentiment at different cut-offs")


```


```{r validate-raw}
# Join raw estimates to election results
raw_estimates_targets <- join_targets(raw_estimates, elex_master)

# Summary statistics of each cut-off
cut_off_stats <- summarise_cut_off_validation(raw_pro_shares_targets)

# Plot raw estimate stats of each cut-off
cut_off_stats %>%
  filter(days_diff < 0) %>%
  ggplot(.,
         aes(x = days_diff, y = abs(mean))) +
  geom_point() +
  geom_smooth(method = lm) +
  facet_wrap(~ cut_off) +
  labs(title = "Mean difference between raw estimate and election results for each cut-off value by days to election")


```

# Add targets and covariates
```{r add-to-senti-day}
# Add targets (election results and polls)
# Join sentiment with target vector, election and polling results
senti_day <- senti_day %>%
  mutate(target_id = row_number())

senti_day <- add_national_level(senti_day)

nrow(senti_day)

senti_day_targets_all <- join_targets(senti_day, targets_master)

# Check which senti regions are not in targets object
senti_day %>% filter(!region_1 %in% targets_master$region_1) %>% distinct(country, region_1)

# Select nearest target (election or poll) for each day
senti_day_targets <- select_nearest_target(senti_day_targets_all)

nrow(senti_day_targets) # number of rows after finding nearest target 

senti_day_targets <- senti_day_targets %>%
  # create variable with country and region_1
  mutate(year = year(date),
         country_and_region_1 = paste0(country, "_", region_1))

# Add GDL covariates
senti_day_targets_covars <- add_gdl_covariates(senti_day_targets, gdl_interpo)

# Check if regions are missing GDL statistics
senti_day_targets_covars %>% filter(is.na(popshare)) %>% distinct(region_1)


```


```{r add-to-senti-region}
# Add targets (election results and polls)



```


# Model 1 MR
```{r model-1-mr}
# Multilevel models trained on polls

# Training data
# Election results
# Elections for each country
senti_targets_covars %>%
  filter(type == "election") %>%
  distinct(country, date_target) %>%
  arrange(country)

train_data_elex <- senti_targets_covars %>%
  # create id to later subset test data
  mutate(id = row_number()) %>%
  filter(type == "election") %>%
  # remove Zimbabwe's 2013 election
  filter(!(country == "Zimbabwe" & year(date) == 2013)) %>%
  arrange(country, region_1, region_2, date_target)

# All elections but the last per country
(train_data_elex_first <- train_data_elex %>%
    group_by(country) %>%
    filter(date_target != max(date_target)) %>%
    ungroup()
)

# Elections to train models on
train_data_elex_first %>%
  #filter(leader_country == "Georgia") %>%
  distinct(leader_country, date_target)

# Last election for each country (to be tested on later)
test_data_elex_last <- senti_targets_covars %>%
  filter(type == "election") %>%
  group_by(country) %>%
  filter(date_target == max(date_target)) %>%
  ungroup()

test_data_elex_last %>%
  distinct(country, date_target)

# Polls before last election per country
train_data_polls <- senti_targets_covars %>%
  filter(type == "poll") %>%
  arrange(country, region_1, region_2, leader) %>%
  mutate(target_before_last_elex = case_when(country == "Nigeria" & date_target < as.Date("2019-02-23") ~ TRUE,
                                             country == "Zimbabwe" & date_target < as.Date("2018-07-03") ~ TRUE,
                                             country == "Georgia" & date_target < as.Date("2013-10-27") ~ TRUE,
                                             country == "Afghanistan" & date_target < as.Date("2019-09-28") ~ TRUE,
                                             country == "Mexico" & date_target < as.Date("2018-07-01") ~ TRUE,
                                             TRUE ~ FALSE)) %>%
  # remove polls after last election
  filter(target_before_last_elex) %>%
  filter(days_diff_abs < 40) %>%
  # remove Zimbabwe's 2013 election
  filter(!(country == "Zimbabwe" & year(date) == 2013))

# Fit models
# Trained on election results
model_1_elex_1 <- lmer(votes_share ~ afinn_mean + (1 | country),
                       data = train_data_elex_first)

model_1_elex_2 <- lmer(votes_share ~ afinn_mean + (1 + afinn_mean | country),
                       data = train_data_elex_first)

# Trained on polls
model_1_polls_1 <- lmer(votes_share ~ afinn_mean + (1 | country),
                        data = train_data_polls)

model_1_polls_2 <- lmer(votes_share ~ afinn_mean + (1 + afinn_mean | country),
                        data = train_data_polls)


```


```{r validate-model-1}
# Validate poll-based models

# Predict model 1
predictions_1 <- test_data_elex_last %>%
  mutate(prediction_1_elex_1 = predict(model_1_elex_1, ., allow.new.levels = TRUE),
         prediction_1_elex_2 = predict(model_1_elex_2, ., allow.new.levels = TRUE),
         prediction_1_polls_1 = predict(model_1_polls_1, ., allow.new.levels = TRUE),
         prediction_1_polls_2 = predict(model_1_polls_2, ., allow.new.levels = TRUE)
         
  )

# Calculate MAE on validation data
(mae_1 <- predictions_1 %>%
  #filter(days_diff_abs < 40) %>%
  mutate(diff_1_elex_1 = abs(prediction_1_elex_1 - votes_share),
         diff_1_elex_2 = abs(prediction_1_elex_2 - votes_share),
         diff_1_polls_1 = abs(prediction_1_polls_1 - votes_share),
         diff_1_polls_2 = abs(prediction_1_polls_2 - votes_share),
  ) %>%
  group_by(country, date_target) %>%
  summarise(across(starts_with("diff"), ~mean(., na.rm = TRUE))) %>%
  ungroup()
)


```

```{r poll-model-2-mrp}
# Model 2
# Multilevel regression and post-stratification (MRP)
model_2_1 <- lmer(votes_share ~ afinn_mean + (1|country_and_region_1),
                  data = train_data_1)

summary(model_2_1)

# Predict on test data
predictions_2 <- predictions %>%
  filter(type == "election") %>%
  filter(days_diff_abs < 10) %>%
  filter(!(country == "Zimbabwe" & year(date) == 2013)) %>%
  mutate(prediction_2_1 = predict(model_2_1, ., allow.new.levels = TRUE)
  )

# Post-stratify using GDL's population share
predictions_2 <- predictions_2 %>%
  transmute(prediction_2_1, popshare/100, prediction_2_1_weighted = prediction_2_1*popshare/100)



```



```{r roc-curve}
# ROC curve

# For example, if difference is less than two percent
# Use existing literature

```


# Tables
```{r table-country-stats}
# Table of country statistics
tweets_stats_country <- tweets_sub %>%
  transmute(leader_country,
            week = floor_date(date, "week"),
            year = year(date),
            week_country = paste0(leader_country, week),
            year_country = paste0(leader_country, year)
  )

add_total <- function(x) { mutate(x, Total = Afghanistan + Georgia + Mexico + Nigeria + Zimbabwe) }

# tweets_total <- tweets_sub %>%
#   mutate(leader_country = "Total")
# 
# tweets_stats_country <- rbind(tweets_stats_country, tweets_total)

# Tweet count per country
(n_tweets_per_country <- tweets_stats_country %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Total tweets") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Average number of tweets per country
(n_weekly_tweets_per_country <- rbind(tweets_stats_country,
                                      tweets_stats_country %>% mutate(leader_country = "Total")) %>%
    group_by(leader_country, week_country) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = mean(n) %>% round(2)) %>%
    mutate(variable = "Average weekly number of tweets") %>%
    pivot_wider(names_from = leader_country, values_from = n)
)

# Number of unique weeks
(n_weeks_per_country <- tweets_stats_country %>%
    group_by(leader_country, week) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of weeks") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Years per country
(n_years_per_country <- tweets_stats_country %>%
    group_by(leader_country, year) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of years") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Subnational regions per country in data
(n_regions_1_per_country <- tweets_sf %>%
    as.data.frame() %>%
    select(-geometry) %>%
    group_by(leader_country, region_1) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of subnational regions/levels") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Number of elections per country
(n_elections_per_country <- elex_master %>%
    group_by(country, elex_date) %>%
    summarise(n = n()) %>%
    group_by(country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of elections") %>%
    pivot_wider(names_from = country, values_from = n) %>%
    add_total()
)

# Number of unique candidacies and leaders
(n_candidates_per_country <- candidates %>%
    group_by(country, name, elex_date) %>%
    summarise(n = n()) %>%
    group_by(country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of elections per country") %>%
    pivot_wider(names_from = country, values_from = n) %>%
    add_total()
)

# Number of polls per country
(n_polls_per_country <- polling_master %>%
    group_by(country, date) %>%
    summarise(n = n()) %>%
    group_by(country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of polls per country") %>%
    pivot_wider(names_from = country, values_from = n) %>%
    add_total()
)

# Combine into table
(by_country_table <- bind_rows(n_tweets_per_country,
                               n_weekly_tweets_per_country,
                               n_weeks_per_country,
                               n_years_per_country,
                               n_regions_1_per_country,
                               #n_regions_2_per_country,
                               n_elections_per_country,
                               n_polls_per_country) %>%
    rename(Name = variable)
)

# Save as csv
#write_csv(by_country_table, file = "output/tables/per_country.csv")


```


# Plots


```{r plot-weekly-tweet-frequency}
# Summarise tweets per week
tweets_n_per_week <- tweets_sub %>%
  group_by(leader_country, leader, week = floor_date(date, "week")) %>%
  summarise(n = n()) %>%
  ungroup()

# Mean number of tweets per week
tweets_n_per_week %>%
  group_by(week) %>%
  summarise(mean = mean(n))

# Plot
ggplot(tweets_n_per_week, aes(x = week, y = n)) +
  geom_col(colour = blue_colour) +
  facet_wrap(~ leader_country,
             scales = "free_y",
             labeller = label_wrap_gen(width = 20),
             #space = "free"
  ) +
  labs(title = "Weekly number of Tweets per country",
       subtitle = "Number of Tweets per week by country of the leader mentioned in the Tweet") +
  theme_devpublicopinion +
  ggsave("output/figures/tweets_n_per_week.png")


```


```{r plot-tweets-by-having-points}
# Number of tweets over time
tweets_sf %>%
  as.data.frame() %>%
  group_by(has_point, year = year(date)) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  mutate(has_point = case_when(has_point ~ "Geotagged",
                               !has_point ~ "Non-geotagged")) %>%
  ggplot(., aes(x = year, y = n)) +
  geom_col(aes(fill = has_point), show.legend = FALSE) +
  facet_wrap(~has_point, scales = "free_y"
  ) +
  scale_y_continuous(labels = comma) +
  labs(title = "Number of tweets with or without coordinates",
       subtitle = "Number of Tweets per year that were geotagged or not by the Twitter users"
  ) +
  theme_devpublicopinion +
  ggsave("output/figures/number_of_tweets_has_point.png")


```


```{r senti-join-stats}
# Share of tweets with no lexicon match for any of their stemmed words
(share_tweets_no_senti <- senti_tweets %>%
   group_by(id, username, language) %>%
   summarise(afinn_mean = mean(afinn_value, na.rm = TRUE)) %>%
   mutate(has_afinn = !is.na(afinn_mean),
          in_english = language == "en") %>%
   group_by(has_afinn, in_english) %>%
   summarise(n = n())
)

```



```{r plot-maps}
# Simply GADM for plotting ease
boundaries_subnational_simp <- boundaries_subnational %>%
  st_simplify(., dTolerance = 0.05)

# Plot geotagged Tweets on map
tweets_geotagged <- tweets_sf %>%
  filter(has_point)

plot_tweets_in_country <- function(plot_country = "Afghanistan"){
  
  ggplot() +
    geom_sf(data = boundaries_subnational_simp %>% filter(country == plot_country),
            fill = NA) +
    geom_sf(data = tweets_geotagged %>% filter(country == plot_country),
            size = 3, shape = 21, fill = blue_colour) +
    labs(title = paste0(plot_country)) +
    theme_devpublicopinion +
    theme(panel.grid.major = element_blank())
  
}

# Plot and combine maps by country with patchwork
(map_afg <- plot_tweets_in_country("Afghanistan"))
map_zwe <- plot_tweets_in_country("Zimbabwe")
map_geo <- plot_tweets_in_country("Georgia")
map_mex <- plot_tweets_in_country("Mexico")
map_nga <- plot_tweets_in_country("Nigeria")


(map_afg | map_mex | map_zwe)/(map_geo | map_nga) +
  plot_annotation(title = "Geotagged Tweets by country and subnational regions",
                  subtitle = "The spatial location of geotagged Tweets that mentions a country leader or election candidate",
                  theme = theme_devpublicopinion
  ) +
  ggsave("output/figures/maps.png")


```



```{r plot-point-mae-by-election}
# Point plot of MAE by elections
# Highlight problematic/special elections (ZWE 2013)


```



```{r plot-eng-speakers}
# English-speakers plot
# Plot different data on English speakers
supp %>%
  ggplot(.,
         aes(x = eng_prop_wiki,
             y = eng_prop) # ethno
  ) +
  geom_point() +
  geom_label_repel(aes(label = paste0(country, " ", year))) +
  labs(title = "Different sources on English speakers per country")

# Plot English speaking population against corruption index
supp %>%
  #filter(wgi_est < 1) %>%
  filter(twitter_users_pc < 0.3) %>%
  ggplot(.,
         aes(x = twitter_users_pc,
             y = eng_prop)) +
  geom_point() +
  geom_label_repel(aes(label = paste0(country, " ", year))) +
  labs(title = "English-speaking share by voice and accountability index")

```


