---
title: "dev-public-opinion"
author: "William Rohde Madsen"
output: html_document
---

# Set up
```{r set-up}
# Load packages
library(tidyverse)
library(devtools)
library(readxl)
library(lubridate)
library(stringr)
library(janitor)
library(zoo)
library(RcppRoll)
library(rgdal) # for shapefiles
library(sf) # manipulating spatial data
library(lme4) # for glmer, etc. modelling
library(httr)
library(ggrepel)
library(reticulate) # using python code in R
library(vroom) # loading json faster
library(ndjson)
library(jsonlite)
library(rvest) # reading html websites
library(maps)
library(ggmap)
library(stars) # rasters
library(maptools)
library(spatstat)
library(koRpus)
library(quanteda)
library(textdata)
library(tidytext)
library(SnowballC)

# Load package functions
devtools::load_all()

```

# Load prepared data
```{r load-data}
# Format data
#source("data-raw/03_master_formatting.R")

# Load formatted data
load("data/formatted_data.RData")

```

# Number of tweets
```{r number-of-tweets}
# Number of tweets over time
tweets_sf %>%
  as.data.frame() %>%
  group_by(week, has_point) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  ggplot(., aes(x = week, y = n, colour = has_point)) +
  geom_line() +
  facet_wrap(~has_point, scales = "free_y") +
  labs(title = "Number of tweets per week with or without coordinates")

# Number of total tweets with or without coordinates
tweets_sf %>%
  as.data.frame() %>%
  group_by(leader_country, has_point) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  ggplot(., aes(x = has_point, y = n, fill = has_point)) +
  geom_col() +
  facet_wrap(~leader_country, scales = "free_y") +
  labs(title = "Number of total tweets with or without coordinates")


```


# Sentiment analysis
```{r prepare-text}
# Create tweets tokens
tweets_tokens <- tweets_sf %>%
  create_tweet_tokens()

```

```{r join-lexicon}
# Join sentiment values by stem
senti_per_token <- join_sentiment_by_stem(tweet_tokens, afinn_stem)

# Share of tweets with no lexicon match for any of their stemmed words
(share_tweets_no_senti <- senti_tweets %>%
    group_by(id, username, language) %>%
    summarise(afinn_mean = mean(afinn_value, na.rm = TRUE)) %>%
    mutate(has_afinn = !is.na(afinn_mean),
           in_english = language == "en") %>%
    group_by(has_afinn, in_english) %>%
    summarise(n = n())
)

```

```{r tweets-per-week}
# Summarise tweets per week
tweets_n_per_week <- tweets_sf %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(country, leader, week = floor_date(date, "week")) %>%
  summarise(n = n()) %>%
  ungroup()

# Mean number of tweets per week
tweets_n_per_week %>%
  group_by(week) %>%
  summarise(mean = mean(n))

# Plot
ggplot(tweets_n_per_week, aes(x = week, y = n, col = leader)) +
  geom_line() +
  geom_hline(yintercept = 100) +
  facet_wrap(~ leader) +
  labs(title = "Tweets per week")

```


```{r senti-per-tweet}
# Calculate sentiment per tweet
# Mean sentiment per tweet
senti_per_tweet <- create_mean_sentiment_per_tweet(senti_per_token)

```

# Raw estimates
```{r raw-estimates}
# Find for-against based on mean sentiment
senti_cut_offs <- create_cut_offs(senti_per_tweet)

# Create an estimate per week per cut off
raw_pro_shares <- find_pro_share(senti_cut_offs, n_roll = 5)

# Plot pro-share by cut-offs
raw_pro_shares %>%
  filter(leader == "Ghani") %>%
  ggplot(., aes(x = date, y = pro_share, colour = leader)) +
  geom_point() +
  geom_line(aes(y = pro_share_roll), colour = "black") +
  facet_wrap(~ cut_off) +
  labs(title = "Raw favourability ratings at different cut-offs")


```

# Train models
```{r train-election}
# Multilevel models trained on election results

# Sentiment per day
(senti_per_day <- senti_per_tweet %>%
   group_by(date, has_point, replies_count, retweets_count, likes_count,
            leader, leader_country, country, region_1, region_2) %>%
   summarise(afinn_mean = mean(afinn_mean, na.rm = TRUE),
             n_tweets = n()) %>%
   ungroup() %>%
   arrange(date, country, region_1, region_2)
)

# Join sentiment with election results
senti_per_day_elex <- join_election_to_tweets(senti_per_day, elex_master)

# Select nearest election for each day
senti_per_day_elex <- select_nearest_election(senti_per_day_elex)

# Model 1
model_1 <- lmer(votes_share ~ afinn_mean + n_tweets + (1|country),
                data = senti_per_day_elex)

summary(model_1)

# Model 2
model_2 <- lmer(votes_share ~ (1 + afinn_mean|country),
                data = senti_per_tweet_elex)

summary(model_2)

# Model 2 with Beauchamp rolling technqiue


```

```{r train-survey}

```

```{r train-alternative}

```


# Validation
```{r validate-raw}
# Join raw estimates to election results
validate_elex_raw <- join_election_to_raw_senti(raw_pro_shares, elex_master)

# Summary statistics of each cut-off
cut_off_stats <- summarise_cut_off_validation(validate_elex_raw)

# Plot raw estimate stats of each cut-off
cut_off_stats %>%
  filter(days_diff < 0) %>%
  ggplot(.,
         aes(x = days_diff, y = abs(mean))) +
  geom_point() +
  geom_smooth(method = lm) +
  facet_wrap(~ cut_off) +
  labs(title = "Mean difference between raw estimate and election results for each cut-off value by days to election")


```



# Various plots
```{r plot}
# Simply GADM for plotting ease
gadm_simp <- gadm %>%
  st_simplify(., dTolerance = 0.1)

# English-speakers plot ------
# Plot different data on English speakers
supp %>%
  ggplot(.,
         aes(x = eng_prop_wiki,
             y = eng_prop) # ethno
  ) +
  geom_point() +
  geom_label_repel(aes(label = paste0(country, " ", year))) +
  labs(title = "Different sources on English speakers per country")

# Plot English speaking population against corruption index
supp %>%
  #filter(wgi_est < 1) %>%
  filter(twitter_users_pc < 0.3) %>%
  ggplot(.,
         aes(x = twitter_users_pc,
             y = eng_prop)) +
  geom_point() +
  geom_label_repel(aes(label = paste0(country, " ", year))) +
  labs(title = "English-speaking share by voice and accountability index")

# Raw tweets plots -----
# Plot number of tweets every week
tweets %>%
  filter(country == "Nigeria") %>%
  mutate(week = floor_date(date, unit = "week"),
         month = floor_date(date, unit = "month")
  ) %>%
  group_by(month, country, leader) %>%
  summarise(n = n()) %>%
  ggplot(.,
         aes(x = month,
             y = n)) +
  geom_col() +
  labs(title = "Number of Tweets mentioning Buhari in Lagos, Nigeria",
       subtitle = paste0(nrow(tweets), " tweets from Lagos")
  ) 


# Map Tweets as points
world1 <- map("world", plot = FALSE, fill = TRUE) %>% sf::st_as_sf()
sf::st_as_sf(map("africa", plot = FALSE, fill = TRUE))

# Nigeria NE
nigeria_sf <- world1 %>% filter(ID == "Nigeria")

tweets_n <- nrow(tweets)
tweets_n_w_points <- nrow(tweets[!is.na(tweets$place_coordinates_0),])

ggplot() +
  geom_sf(data = nigeria_sf) +
  coord_sf(xlim = c(8.5, 9.5), ylim = c(7, 7.7), expand = FALSE) +
  geom_point(data = tweets, aes(x = place_coordinates_0, y = place_coordinates_1),
             size = 0.7) +
  labs(title = "Lagos in Nigeria: Tweets which included point spatial data",
       subtitle = paste0(tweets_n_w_points, " of ", tweets_n, " tweets include spatial data")
  ) +
  theme_bw()


# Methodology plots -----
# Plot get circles
ggplot() +
  geom_sf(data = gadm_simp) +
  geom_sf(data = gadm_circ, fill = NA)


```

