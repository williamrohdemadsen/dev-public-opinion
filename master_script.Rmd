---
title: "dev-public-opinion"
author: "William Rohde Madsen"
output: html_document
---

# Set up
```{r load-packages}
# Load packages
library(tidyverse)
library(devtools)
library(readxl)
library(lubridate)
library(stringr)
library(janitor)
library(zoo)
library(RcppRoll)
library(rgdal) # for shapefiles
library(sf) # manipulating spatial data
library(lme4) # for glmer, etc. modelling
library(httr)
library(ggrepel)
library(reticulate) # using python code in R
library(vroom) # loading json faster
library(ndjson)
library(jsonlite)
library(rvest) # reading html websites
library(maps)
library(ggmap)
library(stars) # rasters
library(maptools)
library(spatstat)
library(koRpus)
library(quanteda)
library(textdata)
library(tidytext)
library(SnowballC)
library(furrr)
library(data.table)
require(scales)
library(patchwork)
library(GGally)
library(broom.mixed)
library(modelr)

# Load package functions
#devtools::load_all()

```

```{r source-scripts}
# Source R scripts
list.files("R", full.names = TRUE) %>%
  purrr::map(source)

```

# Load prepared data
```{r load-data}
# Load formatted data
# Formatted with R scripts in data-raw
load("data/formatted_gadm.RData")

load("data/formatted_supplementary.RData")

load("data/tweets_sf.RData")

tweets_sub <- fread("data/tweets_sub.csv") 

senti_tokens <- fread("data/senti_tokens.csv")

```

# Sentiment analysis

```{r senti-per-tweet}
# Calculate sentiment per Tweet
# Mean sentiment per Tweet
senti_tweet <- calculate_sentiment_per_tweet(senti_tokens)

```

```{r add-regions}
# Add regions to sentiment
senti_tweet_w_region_sf <- add_regions(senti_tweet, boundaries_subnational)

# Convert to data.table()
senti_tweet_w_region <- as.data.table(senti_tweet_w_region_sf) %>%
  select(-geometry)

```


# Sentiment per day
```{r senti-day}
# Sentiment per day
senti_day <- calculate_sentiment_per_day(senti_tweet_w_region)

senti_day

# Regions included in data
senti_day$region_1 %>% unique %>% paste(., collapse = ", ")

```


# Sentiment per region over time
```{r senti-region}
# Sentiment per region adjusted over time
# Based on regions
# average sentiment per region
# using non-point tweets to show trend over time
senti_region <- create_region_adjusted_sentiment(senti_day)

senti_region %>% arrange(region_1) %>% distinct(region_1) %>% paste

# Linear interpolation to make up for missing days
# interpolate_missing_days()

```


# Raw estimates
```{r raw-estimates}
# Find for-against based on mean sentiment
senti_cut_offs <- create_cut_offs(senti_tweet_w_region)

#senti_cut_offs <- senti_cut_offs[1:10000,]

# Create raw number of pros and cons per day
raw_n_day <- calculate_raw_n_per_day(senti_cut_offs)

# Calculate raw estimate per day
raw_day <- calculate_raw_estimate_per_day(raw_n_day, n_roll = 7)

raw_day %>% filter(is.na(country))

# Add national level
raw_day <- add_national_level(raw_day)

# Plot pro-share by cut-offs
raw_day %>%
  filter(leader == "Ghani") %>%
  ggplot(., aes(x = date, y = pro_share)) +
  geom_point(colour = "red") +
  geom_line(aes(y = pro_share_roll), colour = "black") +
  facet_wrap(~ cut_off) +
  labs(title = "Ghani's raw favourability rate by raw estimates and different cut offs",
       subtitle = "Estimated favourability of Afghan leader Ghani by raw sentiment and different cut offs") +
  theme_devpublicopinion


```

```{r add-targets-and-gdl-to-raw}
# Add targets (election results and polls)
# Join sentiment with target vector, election and polling results
raw_day <- raw_day %>%
  mutate(target_id = row_number())

raw_day_targets_all <- join_targets(raw_day, targets_master)

# Check which senti regions are not in targets object
raw_day %>% filter(!region_1 %in% targets_master$region_1) %>% distinct(country, region_1)

# Select nearest target (election or poll) for each day
raw_day_targets <- select_nearest_target(raw_day_targets_all)

# Compare rows
nrow(raw_day)
nrow(raw_day_targets)

# Create variable with country and region_1
raw_day_targets <- raw_day_targets %>%
  mutate(year = year(date),
         country_and_region_1 = paste0(country, "_", region_1))

# Add GDL covariates
raw_day_targets_covars <- add_gdl_covariates(raw_day_targets, gdl_interpo)

# Check if regions are missing GDL statistics
raw_day_targets_covars %>% filter(is.na(popshare)) %>% distinct(region_1)


```


```{r validate-raw}
# Validate raw

# Summary statistics of each cut-off
raw_mae <- mae_by_cut_offs(raw_day_targets_covars, type = "election", days_diff_less = 10)

# Plot raw estimate stats of each cut-off
raw_mae %>%
  mutate(country_elex = paste0(country, ", ", format(date_target, "%B %Y"))) %>%
  ggplot(.,
         aes(x = cut_off, y = mean*100)) +
  geom_col() +
  #geom_smooth(method = lm) +
  facet_wrap(~ country_elex) +
  labs(title = "Mean absolute error of 'raw' electoral estimates at different AFINN cut offs",
       subtitle = "Mean absolute error (MAE) of election estimates based on 'raw' AFINN sentiment, percentage points",
       x = "Cut off values",
       y = "MAE"
  ) +
  theme_devpublicopinion


```

# Add targets and GDL for models
```{r add-to-senti-day}
# Add targets (election results and polls)
# Join sentiment with target vector, election and polling results
senti_day <- senti_day %>%
  mutate(target_id = row_number())

# Add national level to join targets
senti_day <- add_national_level(senti_day)

senti_day_targets_all <- join_targets(senti_day, targets_master)

# Check which senti regions are not in targets object
senti_day %>% filter(!region_1 %in% targets_master$region_1) %>% distinct(country, region_1)

# Select nearest target (election or poll) for each day
senti_day_targets <- select_nearest_target(senti_day_targets_all)

# Compare rows
nrow(senti_day)
nrow(senti_day_targets)

# Create variable with country and region_1
senti_day_targets <- senti_day_targets %>%
  mutate(year = year(date),
         country_and_region_1 = paste0(country, "_", region_1))

# Add GDL covariates
senti_day_targets_covars <- add_gdl_covariates(senti_day_targets, gdl_interpo)

# Check if regions are missing GDL statistics
senti_day_targets_covars %>% filter(is.na(popshare)) %>% distinct(region_1)

```


```{r add-to-senti-region}
# Add row_number to join targets
senti_region <- senti_region %>%
  mutate(target_id = row_number())

# Fix missing national and region column
senti_region <- add_national_level(senti_region)

# Add targets (election results and polls)
senti_region_targets_all <- join_targets(senti_region, targets_master, by_region = FALSE)

# Check which senti regions are not in targets object
senti_region %>% filter(!region_1 %in% targets_master$region_1) %>% distinct(country, region_1)

# Select nearest target (election or poll) for each day
senti_region_targets <- select_nearest_target(senti_region_targets_all)

# Compare rows
# New rows indicate targets being of equal diff days to a sentiment day
nrow(senti_region)
nrow(senti_region_targets)

# Create variable with country and region_1
senti_region_targets <- senti_region_targets %>%
  mutate(year = year(date),
         country_and_region_1 = paste0(country, "_", region_1))

# Add GDL covariates
senti_region_targets_covars <- add_gdl_covariates(senti_region_targets, gdl_interpo)

# Check if regions are missing GDL statistics
senti_region_targets_covars %>% filter(is.na(popshare)) %>% distinct(region_1)


```

```{r print-elex-per-country}
# Elections for each country
senti_region_targets_covars %>%
  filter(type == "election") %>%
  distinct(country, date_target) %>%
  arrange(country)

```

# Multilevel regression
```{r training-data}
# Training data
# Sentiment day
train_data_elex_first_day <- create_training_data(senti_day_targets_covars,
                                                  type = "elex", less_than_days_diff = 100)
train_data_polls_day <- create_training_data(senti_day_targets_covars,
                                             type = "polls", less_than_days_diff = 100)

# Sentiment region
train_data_elex_first_region <- create_training_data(senti_region_targets_covars,
                                                     type = "elex", less_than_days_diff = 100)
train_data_polls_region <- create_training_data(senti_region_targets_covars,
                                                type = "polls", less_than_days_diff = 100)


```


```{r linear-models}
# Linear models
fit_lm_1_for_country <- function(train_data){ lm(votes_share ~ afinn_mean, data = train_data) }
fit_lm_2_for_country <- function(train_data){ lm(votes_share ~ n_likes_mean, data = train_data) }
fit_lm_3_for_country <- function(train_data){ lm(votes_share ~ afinn_mean*n_likes_mean, data = train_data) }

# Fit models on elections
lm_d_e <- train_data_elex_first_day %>%
  group_by(country) %>% 
  nest() %>%
  mutate(lm_1_d_e = purrr::map(data, ~fit_lm_1_for_country(.x)),
         lm_2_d_e = purrr::map(data, ~fit_lm_2_for_country(.x)),
         lm_3_d_e = purrr::map(data, ~fit_lm_3_for_country(.x))
  ) %>%
  ungroup() %>%
  pivot_longer(cols = c(lm_1_d_e, lm_2_d_e, lm_3_d_e), names_to = "model_name", values_to = "model") %>%
  mutate(model_type = "day") %>%
  rename(model_country = country)

lm_d_e

```


```{r multi-models}
# Multilevel models

# Functions for multilevel regression
fit_mr_1_day <- function(train_data){ lmer(votes_share ~ afinn_mean + (1 | country), data = train_data) }

fit_mr_2_day <- function(train_data){ lmer(votes_share ~ n_likes_mean + (1 | country), data = train_data) }

fit_mr_3_day <- function(train_data){ lmer(votes_share ~ afinn_mean*n_likes_mean + (1 | country),
                                           data = train_data) }

fit_mr_1_region <- function(train_data){
  lmer(votes_share ~ afinn_mean_daily + afinn_mean_region + (1 | country), data = train_data)
}

fit_mr_2_region <- function(train_data){
  lmer(votes_share ~ n_likes_mean + (1 | country), data = train_data)
}

fit_mr_3_region <- function(train_data){
  lmer(votes_share ~ afinn_mean_daily*n_likes_mean + afinn_mean_region + (1 | country), data = train_data)
}

# Fit multilevel models on elections
# Day
mr_d_e <- train_data_elex_first_day %>%
  nest(data = everything()) %>%
  mutate(mr_1_d_e = purrr::map(data, ~fit_mr_1_day(.x)),
         mr_2_d_e = purrr::map(data, ~fit_mr_2_day(.x)),
         mr_3_d_e = purrr::map(data, ~fit_mr_3_day(.x))
  ) %>%
  pivot_longer(cols = c(2:4), names_to = "model_name", values_to = "model") %>%
  mutate(model_type = "day")


# Region
mr_r_e <- train_data_elex_first_region %>%
  nest(data = everything()) %>%
  mutate(mr_1_r_e = purrr::map(data, ~fit_mr_1_region(.x)),
         mr_2_r_e = purrr::map(data, ~fit_mr_2_region(.x)),
         mr_3_r_e = purrr::map(data, ~fit_mr_3_region(.x))
  ) %>%
  pivot_longer(cols = c(2:4), names_to = "model_name", values_to = "model") %>%
  mutate(model_type = "region")


# Fit multilevel models on polls
# Day
mr_d_p <- train_data_polls_day %>%
  nest(data = everything()) %>%
  mutate(mr_1_d_p = purrr::map(data, ~fit_mr_1_day(.x)),
         mr_2_d_p = purrr::map(data, ~fit_mr_2_day(.x)),
         mr_3_d_p = purrr::map(data, ~fit_mr_3_day(.x))
  ) %>%
  pivot_longer(cols = c(2:4), names_to = "model_name", values_to = "model") %>%
  mutate(model_type = "day")


# Region
mr_r_p <- train_data_polls_region %>%
  nest(data = everything()) %>%
  mutate(mr_1_r_p = purrr::map(data, ~fit_mr_1_region(.x)),
         mr_2_r_p = purrr::map(data, ~fit_mr_2_region(.x)),
         mr_3_r_p = purrr::map(data, ~fit_mr_3_region(.x))
  ) %>%
  pivot_longer(cols = c(2:4), names_to = "model_name", values_to = "model") %>%
  mutate(model_type = "region")


```

# All models
```{r bind-all-models}
# Join countries to multilevel models
# Required before joining all models to test data
countries_to_join <- senti_day_targets_covars %>%
  distinct(country) %>%
  mutate(join_id = 1)

models_mr <- bind_rows(mr_d_e,
                       mr_d_p,
                       mr_r_e,
                       mr_r_p) %>%
  select(-data) %>%
  mutate(join_id = 1)

#models_mr <- left_join(countries_to_join, models_mr)

# Bind all models together
# Multilevel and linear
models_master <- bind_rows(lm_d_e,
                           models_mr) %>%
  select(-data, -join_id) %>%
  mutate(model_no = row_number())

head(models_master)

models_master %>% filter(is.na(model_country))

# Use tidy to get model statistics
# broom and broom.mixed packages
models_stats <- models_master %>%
  mutate(model_tidy = purrr::map(model, broom.mixed::tidy)) %>%
  unnest(model_tidy)

# Add names for models


```


```{r model-predictions}
# Predictions

# Create test data
test_day <- create_test_data(senti_day_targets_covars, choose_type = "election") %>%
  mutate(test_type = "day")

test_region <- create_test_data(senti_region_targets_covars, choose_type = "election") %>%
  mutate(test_type = "region")

test_master <- bind_rows(test_day,
                         test_region) %>%
  mutate(test_id = row_number())

# Add models to test data
#test_master_2 <- add_models_to_test_data(test_master,
#                                         models_master)


# Get estimates for each test row by different models
prediction_raw <- purrr::map(models_master$model, ~predict(.x, test_master, allow.new.levels = TRUE))

# Pivot longer
prediction <- prediction_raw %>%
  bind_rows() %>%
  mutate(model_no = row_number()) %>%
  pivot_longer(cols = c(1:ncol(.)-1), names_to = "test_id", values_to = "prediction") %>%
  mutate(test_id = as.integer(test_id)) %>%
  left_join(.,
            models_master %>% select(-model),
            by = "model_no")

# Add estimates to test data
# Allows us to calculate difference between actual vote share and estimated share
prediction_master <- left_join(test_master, prediction, by = "test_id")

# Remove rows if test type is not model type (region or day) 
# or if test country is not model country (except for multilevel models with no model country)
prediction_master <- prediction_master %>%
  filter(test_type == model_type) %>%
  filter(is.na(model_country) | model_country == country)


```


```{r add-post}
# Add post-stratified estimates with GDL's popshare variable
prediction_master <- prediction_master %>%
  mutate(across(starts_with("prediction"), ~.*popshare, .names = "{.col}_post"))


```


```{r calculate-mae}
# Calculate error
prediction_master <- prediction_master %>%
  mutate(error = prediction - votes_share,
         error_abs = abs(error))

# Find MAE
prediction_master %>%
  filter(days_diff_abs < 10) %>%
  group_by(country, model_name) %>%
  summarise(mae = mean(error_abs, na.rm = TRUE))


# Unique models
prediction_master$model %>% unique()


```


# Validation
```{r validate-mr-data}
# Plots for validating MR estimates
prediction_master

# Calculate MAE by model and country
mae_by_model_country <- prediction_master %>%
  filter(days_diff_abs < 10) %>%
  group_by(model_name, country) %>%
  summarise(mae = mean(error_abs, na.rm = TRUE),
            n_regions = n_distinct(region_1)) %>%
  ungroup()

# Add country average and model average levels
mae_by_model_country <- bind_rows(mae_by_model_country,
                                  mae_by_model_country %>%
                                    mutate(country = "Country average") %>%
                                    group_by(model_name, country) %>%
                                    summarise(mae = mean(mae)),
                                  mae_by_model_country %>%
                                    mutate(model = "Model average") %>%
                                    group_by(model_name, country) %>%
                                    summarise(mae = mean(mae))
)

# Calculate MAE by model and region
mae_by_model_region <- prediction_master %>%
  filter(days_diff_abs < 10) %>%
  group_by(model_name, country, region_1, region_2) %>%
  summarise(votes_share = mean(votes_share, na.rm = TRUE),
            prediction = mean(prediction, na.rm = TRUE),
            mae = mean(error_abs, na.rm = TRUE)
  ) %>%
  ungroup()

# Add model average level
(mae_by_model_region <- bind_rows(mae_by_model_region,
                                     mae_by_model_region %>%
                                       mutate(model_name = "Model average") %>%
                                       group_by(model_name, country, region_1, region_2) %>%
                                       summarise(votes_share = mean(votes_share, na.rm = TRUE),
                                                 prediction = mean(prediction, na.rm = TRUE),
                                                 mae = mean(mae, na.rm = TRUE))
) #%>% filter(model == "Model average")
)


```


```{r validate-plots}
# Plot MAE by model and region
mae_by_model_country %>%
  mutate(model_name = as.factor(model_name),
         country = reorder_within(country, mae, model_name)) %>%
  ggplot(aes(x = country, y = mae, fill = model_name)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~model_name, scales = "free_y") +
  coord_flip() +
  scale_x_reordered()

# Plot all predictions as points
prediction_master_sub <- prediction_master %>%
  filter(days_diff_abs < 15)

ggplot(prediction_master_sub,
       aes(x = prediction,
           y = votes_share)) +
  geom_point(aes(colour = country),
             size = 3,
             #show.legend = FALSE
  ) +
  facet_wrap(~model_name) +
  geom_abline(intercept = 0, slope = 1) +
  scale_x_continuous(limits = c(0, 1)) +
  scale_colour_discrete(name = "") +
  theme_devpublicopinion +
  labs(title = "Model predictions against actual vote shares",
       subtitle = "Different model predictions (x-axis) against latest actual election vote shares (y-axis); diagonal line shows perfect predictions (error equals 0)",
       x = "Prediction",
       y = "Votes share")


# Plot average predictions by region as points
ggplot(mae_by_model_region,
       aes(x = prediction,
           y = votes_share)) +
  geom_point(aes(colour = country),
             size = 3,
             #show.legend = FALSE
  ) +
  facet_wrap(~model_name) +
  geom_abline(intercept = 0, slope = 1) +
  scale_x_continuous(limits = c(0, 1)) +
  scale_colour_discrete(name = "") +
  theme_devpublicopinion +
  labs(title = "Average model predictions against actual vote shares by region",
       subtitle = "Different model estimates (x-axis) against latest actual election vote shares (y-axis), averaged by subnational region;\ndiagonal line shows perfect predictions (where error equals 0)",
       x = "Prediction",
       y = "Votes share") 


```



```{r plot-estimates-correlation}
# Correlation between estimates and features
prediction_master_num <- prediction_master %>%
  select(where(is.numeric))

# Calculate correlation
prediction_master_cor <- prediction_master_num %>%
  cor()

prediction_master_cor <- prediction_master_cor %>%
  as_data_frame() %>%
  mutate(x = colnames(prediction_master_num)) %>%
  pivot_longer(names_to = "y", values_to = "value", popshare:error_abs)

prediction_master_cor %>%
  arrange(x, y) %>%
  ggplot(aes(x = x, y = y, fill = value)) + 
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name = "Pearson\nCorrelation") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  coord_fixed() +
  labs(x = "feature", 
       y = "feature",
       title = "Correlation between features", 
       caption = "Source: Pima Indians Diabetes Database")


# Scatterplot matrix
ggpairs(prediction_master, 
        columns = c(eye, cellphone, phone),
        alpha = 0.7) +
  labs(x = "feature", 
       y = "feature",
       title = "Scatterplot matrix", 
       caption = "Source: Pima Indians Diabetes Database")

```




# Predictions over time
```{r predictions-over-time}
# Use models to estimate votes share over time


```


# Tables
```{r table-country-stats}
# Table of country statistics
tweets_stats_country <- tweets_sub %>%
  transmute(leader_country,
            week = floor_date(date, "week"),
            year = year(date),
            week_country = paste0(leader_country, week),
            year_country = paste0(leader_country, year)
  )

add_total <- function(x) { mutate(x, Total = Afghanistan + Georgia + Mexico + Nigeria + Zimbabwe) }

# tweets_total <- tweets_sub %>%
#   mutate(leader_country = "Total")
# 
# tweets_stats_country <- rbind(tweets_stats_country, tweets_total)

# Tweet count per country
(n_tweets_per_country <- tweets_stats_country %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Total tweets") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Average number of tweets per country
(n_weekly_tweets_per_country <- rbind(tweets_stats_country,
                                      tweets_stats_country %>% mutate(leader_country = "Total")) %>%
    group_by(leader_country, week_country) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = mean(n) %>% round(2)) %>%
    mutate(variable = "Average weekly number of tweets") %>%
    pivot_wider(names_from = leader_country, values_from = n)
)

# Number of unique weeks
(n_weeks_per_country <- tweets_stats_country %>%
    group_by(leader_country, week) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of weeks") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Years per country
(n_years_per_country <- tweets_stats_country %>%
    group_by(leader_country, year) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of years") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Subnational regions per country in data
(n_regions_1_per_country <- tweets_sf %>%
    as.data.frame() %>%
    select(-geometry) %>%
    group_by(leader_country, region_1) %>%
    summarise(n = n()) %>%
    group_by(leader_country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of subnational regions/levels") %>%
    pivot_wider(names_from = leader_country, values_from = n) %>%
    add_total()
)

# Number of elections per country
(n_elections_per_country <- elex_master %>%
    group_by(country, elex_date) %>%
    summarise(n = n()) %>%
    group_by(country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of elections") %>%
    pivot_wider(names_from = country, values_from = n) %>%
    add_total()
)

# Number of unique candidacies and leaders
(n_candidates_per_country <- candidates %>%
    group_by(country, name, elex_date) %>%
    summarise(n = n()) %>%
    group_by(country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of elections per country") %>%
    pivot_wider(names_from = country, values_from = n) %>%
    add_total()
)

# Number of polls per country
(n_polls_per_country <- polling_master %>%
    group_by(country, date) %>%
    summarise(n = n()) %>%
    group_by(country) %>%
    summarise(n = n()) %>%
    mutate(variable = "Number of polls per country") %>%
    pivot_wider(names_from = country, values_from = n) %>%
    add_total()
)

# Combine into table
(by_country_table <- bind_rows(n_tweets_per_country,
                               n_weekly_tweets_per_country,
                               n_weeks_per_country,
                               n_years_per_country,
                               n_regions_1_per_country,
                               #n_regions_2_per_country,
                               n_elections_per_country,
                               n_polls_per_country) %>%
    rename(Name = variable)
)

# Save as csv
#write_csv(by_country_table, file = "output/tables/per_country.csv")


```



```{r model-tabel}
# Table to compare models


#tidy()

```


# Plots

```{r plot-polls-and-elex}
# Plot traditional polling and election results

# Subset database to include national level rows, only polls
poll_plot_data <- targets_master %>%
  filter(name %in% candidates$name) %>%
  filter(region_1 == "National") %>%
  filter(type == "poll") %>%
  mutate(votes_share = votes_share*100)

# Add US polls for comparison
poll_plot_data <- bind_rows(poll_plot_data,
                            polling_us %>%
                              mutate(votes_share = votes_share*100) %>%
                              filter(year(date_target) > 2006))

# Plot
ggplot(poll_plot_data,
       aes(x = date_target,
           y = votes_share)) +
  geom_point(aes(colour = name), show.legend = FALSE,
             size = 3, shape = 20) +
  geom_label_repel(data = poll_plot_data %>% group_by(name) %>% slice_sample(n = 1),
                   min.segment.length = 0.5,
                   size = 5,
                   aes(x = date_target, y = votes_share, label = name)) +
  facet_wrap(~country# , scales = "free"
  ) +
  theme_devpublicopinion +
  labs(title = "Polling for developing countries is sparce over time",
       subtitle = "% vote share, point for each traditional polling collected by country; numbers of polls included in this figure are not exhaustive",
       x = NULL,
       y = "%, vote share")


```

```{r plot-model-estimates-vs-polls-and-elex}
# Plot model estimates versus polling and election results



```


```{r plot-weekly-tweet-frequency}
# Summarise tweets per week
tweets_n_per_week <- tweets_sub %>%
  group_by(leader_country, leader, week = floor_date(date, "week")) %>%
  summarise(n = n()) %>%
  ungroup()

# Mean number of tweets per week
tweets_n_per_week %>%
  group_by(week) %>%
  summarise(mean = mean(n))

# Plot
ggplot(tweets_n_per_week, aes(x = week, y = n)) +
  geom_col(colour = blue_colour) +
  facet_wrap(~ leader_country,
             scales = "free_y",
             labeller = label_wrap_gen(width = 20),
             #space = "free"
  ) +
  labs(title = "Weekly number of Tweets per country",
       subtitle = "Number of Tweets per week by country of the leader mentioned in the Tweet") +
  theme_devpublicopinion +
  ggsave("output/figures/tweets_n_per_week.png")


```


```{r plot-tweets-by-having-points}
# Number of tweets over time
tweets_sf %>%
  as.data.frame() %>%
  group_by(has_point, year = year(date)) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  mutate(has_point = case_when(has_point ~ "Geotagged",
                               !has_point ~ "Non-geotagged")) %>%
  ggplot(., aes(x = year, y = n)) +
  geom_col(aes(fill = has_point), show.legend = FALSE) +
  facet_wrap(~has_point, scales = "free_y"
  ) +
  scale_y_continuous(labels = comma) +
  labs(title = "Number of tweets with or without coordinates",
       subtitle = "Number of Tweets per year that were geotagged or not by the Twitter users"
  ) +
  theme_devpublicopinion +
  ggsave("output/figures/number_of_tweets_has_point.png")


```


```{r senti-join-stats}
# Share of tweets with no lexicon match for any of their stemmed words
(share_tweets_no_senti <- senti_tweets %>%
   group_by(id, username, language) %>%
   summarise(afinn_mean = mean(afinn_value, na.rm = TRUE)) %>%
   mutate(has_afinn = !is.na(afinn_mean),
          in_english = language == "en") %>%
   group_by(has_afinn, in_english) %>%
   summarise(n = n())
)

```



```{r plot-maps}
# Simply GADM for plotting ease
boundaries_subnational_simp <- boundaries_subnational %>%
  st_simplify(., dTolerance = 0.05)

# Plot geotagged Tweets on map
tweets_geotagged <- tweets_sf %>%
  filter(has_point)

plot_tweets_in_country <- function(plot_country = "Afghanistan"){
  
  ggplot() +
    geom_sf(data = boundaries_subnational_simp %>% filter(country == plot_country),
            fill = NA) +
    geom_sf(data = tweets_geotagged %>% filter(country == plot_country),
            size = 3, shape = 21, fill = blue_colour) +
    labs(title = paste0(plot_country)) +
    theme_devpublicopinion +
    theme(panel.grid.major = element_blank())
  
}

# Plot and combine maps by country with patchwork
(map_afg <- plot_tweets_in_country("Afghanistan"))
map_zwe <- plot_tweets_in_country("Zimbabwe")
map_geo <- plot_tweets_in_country("Georgia")
map_mex <- plot_tweets_in_country("Mexico")
map_nga <- plot_tweets_in_country("Nigeria")


(map_afg | map_mex | map_zwe)/(map_geo | map_nga) +
  plot_annotation(title = "Geotagged Tweets by country and subnational regions",
                  subtitle = "The spatial location of geotagged Tweets that mentions a country leader or election candidate",
                  theme = theme_devpublicopinion
  ) +
  ggsave("output/figures/maps.png")


```

```{r plot-gdl-stats}
# Plot GDL indicators by country
gdl_interpo %>%
  #pivot_longer(cols = c(eye, popshare, phone, cellphone)) %>%
  #filter(gadm_region == "National") %>%
  ggplot(.,
         aes(x = phone,
             fill = country)) +
  geom_boxplot() +
  facet_wrap(~year)

```


```{r plot-geotagged-volume-by-popshare}
# Plot geotagged share of Tweets by actual population
tweets_sf_df <- tweets_sf %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(year = year(date))

# Fix national level
tweets_sf_df <- add_national_level(tweets_sf_df)

# Calculate geotagged Tweets frequency and share
geotagged_volume <- tweets_sf_df %>%
  group_by(year, country, region_1, region_2, has_point) %>%
  summarise(tweets_region_2_n = n()) %>%
  filter(has_point & region_1 != "National" | !has_point) %>% # remove points outside of country
  filter(has_point) %>%
  group_by(year, country) %>%
  mutate(tweets_national_share = tweets_region_2_n/sum(tweets_region_2_n)) %>%
  ungroup()

# Add GDL statistics (targets)
geotagged_volume <- add_gdl_covariates(geotagged_volume, gdl_interpo)

geotagged_volume

geotagged_volume %>%
  group_by(year, country) %>%
  summarise(popshare = sum(popshare, na.rm = TRUE)) %>%
  arrange(-popshare)

# Plot by country
ggplot(geotagged_volume,
       aes(x = tweets_national_share,
           y = popshare)) +
  geom_point(aes(colour = country), show.legend = FALSE) +
  geom_label_repel(data = geotagged_volume %>%
                     filter(tweets_national_share/popshare > 3) %>%
                     group_by(country) %>%
                     slice_sample(n = 1),
                   aes(x = tweets_national_share,
                       y = popshare,
                       label = region_1),
                   min.segment.length = 0.5,
                   size = 5) +
  facet_wrap(~country) +
  labs(title = "Share of geotagged Tweets in subnational region by actual population share") +
  theme_devpublicopinion


# Plot over time
# if the correlation becomes closer to one, estimates may get less biased?
ggplot(geotagged_volume,
       aes(x = tweets_national_share,
           y = popshare)) +
  geom_point(aes(colour = country), show.legend = FALSE) +
  geom_smooth(method = "lm") +
  # geom_label_repel(data = geotagged_volume %>%
  #                    filter(tweets_national_share/popshare > 3) %>%
  #                    group_by(country) %>%
  #                    slice_sample(n = 1),
  #                  aes(x = tweets_national_share,
  #                      y = popshare,
  #                      label = region_1),
  #                  min.segment.length = 0.5,
  #                  size = 5) +
  facet_wrap(~year) +
  scale_x_continuous(limits = c(0, 1)) +
  scale_y_continuous(limits = c(0, 1)) +
  labs(title = "Share of geotagged Tweets in subnational region by actual population share") +
  theme_devpublicopinion


```





```{r plot-eng-speakers}
# English-speakers plot
# Plot different data on English speakers
supp %>%
  ggplot(.,
         aes(x = eng_prop_wiki,
             y = eng_prop) # ethno
  ) +
  geom_point() +
  geom_label_repel(aes(label = paste0(country, " ", year))) +
  labs(title = "Different sources on English speakers per country")

# Plot English speaking population against corruption index
supp %>%
  #filter(wgi_est < 1) %>%
  filter(twitter_users_pc < 0.3) %>%
  ggplot(.,
         aes(x = twitter_users_pc,
             y = eng_prop)) +
  geom_point() +
  geom_label_repel(aes(label = paste0(country, " ", year))) +
  labs(title = "English-speaking share by voice and accountability index")

```


